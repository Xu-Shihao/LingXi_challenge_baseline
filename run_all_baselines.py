#!/usr/bin/env python3
"""
ç²¾ç¥ç–¾ç—…è¾…åŠ©è¯Šæ–­ç»“æœé¢„æµ‹ - Baselineè¿è¡Œè„šæœ¬

è¿è¡Œæ‰€æœ‰baselineæ¨¡å‹ï¼š
1. æ•°æ®é¢„å¤„ç†
2. TF-IDF + ä¼ ç»Ÿæœºå™¨å­¦ä¹ 
3. ChineseBERT fine-tuning
4. Qwen3 zero-shot

ä½œè€…: Assistant
"""

import os
import sys
import json
import pandas as pd
import argparse
from datetime import datetime
import traceback

# æ·»åŠ å½“å‰ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

def run_data_preprocessing():
    """è¿è¡Œæ•°æ®é¢„å¤„ç†"""
    print("\n" + "="*60)
    print("æ­¥éª¤ 1: æ•°æ®é¢„å¤„ç†")
    print("="*60)
    
    try:
        from data_preprocessing import main as preprocess_main
        preprocess_main()
        print("âœ“ æ•°æ®é¢„å¤„ç†å®Œæˆ")
        return True
    except Exception as e:
        print(f"âŒ æ•°æ®é¢„å¤„ç†å¤±è´¥: {e}")
        traceback.print_exc()
        return False

def run_tfidf_baseline():
    """è¿è¡ŒTF-IDF baseline"""
    print("\n" + "="*60)
    print("æ­¥éª¤ 2: TF-IDF Baseline")
    print("="*60)
    
    try:
        from models.tfidf_baseline import main as tfidf_main
        tfidf_main()
        print("âœ“ TF-IDF baselineå®Œæˆ")
        return True
    except Exception as e:
        print(f"âŒ TF-IDF baselineå¤±è´¥: {e}")
        traceback.print_exc()
        return False

def run_chinesebert_baseline():
    """è¿è¡ŒChineseBERT baseline"""
    print("\n" + "="*60)
    print("æ­¥éª¤ 3: ChineseBERT Baseline")
    print("="*60)
    
    try:
        from models.chinesebert_baseline import main as bert_main
        bert_main()
        print("âœ“ ChineseBERT baselineå®Œæˆ")
        return True
    except Exception as e:
        print(f"âŒ ChineseBERT baselineå¤±è´¥: {e}")
        traceback.print_exc()
        return False

def run_qwen3_baseline():
    """è¿è¡ŒQwen3 zero-shot baseline"""
    print("\n" + "="*60)
    print("æ­¥éª¤ 4: Qwen3 Zero-shot Baseline")
    print("="*60)
    
    try:
        from models.qwen3_zeroshot import main as qwen3_main
        qwen3_main()
        print("âœ“ Qwen3 zero-shot baselineå®Œæˆ")
        return True
    except Exception as e:
        print(f"âŒ Qwen3 zero-shot baselineå¤±è´¥: {e}")
        traceback.print_exc()
        return False

def display_feature_importance():
    """æ˜¾ç¤ºTF-IDFæ¨¡å‹çš„ç‰¹å¾é‡è¦æ€§ä¿¡æ¯"""
    results_dir = 'results'
    
    # æŸ¥æ‰¾æ‰€æœ‰ç‰¹å¾é‡è¦æ€§æ–‡ä»¶
    feature_files = []
    for filename in os.listdir(results_dir):
        if filename.startswith('tfidf_') and filename.endswith('_top_features.json'):
            feature_files.append(filename)
    
    if not feature_files:
        print("æœªæ‰¾åˆ°ç‰¹å¾é‡è¦æ€§æ–‡ä»¶")
        return
    
    print(f"\n{'='*60}")
    print("TF-IDF æ¨¡å‹ç‰¹å¾é‡è¦æ€§åˆ†æ")
    print(f"{'='*60}")
    
    for feature_file in feature_files:
        model_type = feature_file.replace('tfidf_', '').replace('_top_features.json', '')
        print(f"\n--- {model_type.upper()} æ¨¡å‹ ---")
        
        feature_path = os.path.join(results_dir, feature_file)
        try:
            with open(feature_path, 'r', encoding='utf-8') as f:
                features_info = json.load(f)
            
            for label_name, features in features_info.items():
                print(f"\n{label_name} - Top 10 é‡è¦ç‰¹å¾:")
                for feature_info in features[:10]:  # æ˜¾ç¤ºå‰10ä¸ª
                    print(f"  {feature_info['rank']:2d}. {feature_info['feature']:25s} (é‡è¦æ€§: {feature_info['importance']:.4f})")
        except Exception as e:
            print(f"è¯»å–ç‰¹å¾æ–‡ä»¶ {feature_file} æ—¶å‡ºé”™: {e}")

def collect_and_compare_results():
    """æ”¶é›†å¹¶æ¯”è¾ƒæ‰€æœ‰æ¨¡å‹çš„ç»“æœ"""
    print("\n" + "="*60)
    print("æ­¥éª¤ 5: ç»“æœæ”¶é›†ä¸æ¯”è¾ƒ")
    print("="*60)
    
    results_dir = 'results'
    if not os.path.exists(results_dir):
        print("âŒ ç»“æœç›®å½•ä¸å­˜åœ¨")
        return False
    
    # æ”¶é›†ç»“æœ
    all_results = {}
    
    # TF-IDFç»“æœï¼ˆå¤šæ ‡ç­¾ç‰ˆæœ¬ï¼‰
    tfidf_comparison_file = os.path.join(results_dir, 'tfidf_multilabel_models_comparison.csv')
    if os.path.exists(tfidf_comparison_file):
        tfidf_df = pd.read_csv(tfidf_comparison_file)
        for idx, row in tfidf_df.iterrows():
            model_name = row['Model']
            all_results[model_name] = {
                'Hamming Loss': row['Hamming Loss'],
                'Jaccard (Micro)': row['Jaccard (Micro)'],
                'F1 (Micro)': row['F1 (Micro)'],
                'F1 (Macro)': row['F1 (Macro)'],
                'F1 (Weighted)': row['F1 (Weighted)']
            }
    
    # æ˜¾ç¤ºç‰¹å¾é‡è¦æ€§ä¿¡æ¯
    display_feature_importance()
    
    # å…¼å®¹æ—§ç‰ˆTF-IDFç»“æœ
    old_tfidf_file = os.path.join(results_dir, 'tfidf_models_comparison.csv')
    if os.path.exists(old_tfidf_file):
        old_tfidf_df = pd.read_csv(old_tfidf_file, index_col=0)  # æŒ‡å®šç¬¬ä¸€åˆ—ä¸ºç´¢å¼•
        for model_type in old_tfidf_df.index:
            model_name = f"TF-IDF + {str(model_type).upper()}"
            row = old_tfidf_df.loc[model_type]
            all_results[model_name] = {
                'Accuracy': row['Accuracy'],
                'F1 (weighted)': row['F1 (weighted)'],
                'F1 (macro)': row['F1 (macro)']
            }
    
    # ChineseBERTç»“æœ
    bert_results_file = os.path.join(results_dir, 'chinesebert_results.json')
    if os.path.exists(bert_results_file):
        with open(bert_results_file, 'r', encoding='utf-8') as f:
            bert_results = json.load(f)
            all_results['ChineseBERT'] = {
                'Accuracy': bert_results['accuracy'],
                'F1 (weighted)': bert_results['f1_weighted'],
                'F1 (macro)': bert_results['f1_macro']
            }
    
    # Qwen3ç»“æœ
    qwen3_results_file = os.path.join(results_dir, 'qwen3_results.json')
    if os.path.exists(qwen3_results_file):
        with open(qwen3_results_file, 'r', encoding='utf-8') as f:
            qwen3_results = json.load(f)
            all_results['Qwen3 Zero-shot'] = {
                'Accuracy': qwen3_results['accuracy'],
                'F1 (weighted)': qwen3_results['f1_weighted'],
                'F1 (macro)': qwen3_results['f1_macro']
            }
    
    if not all_results:
        print("âŒ æœªæ‰¾åˆ°ä»»ä½•ç»“æœæ–‡ä»¶")
        return False
    
    # åˆ›å»ºæ¯”è¾ƒè¡¨æ ¼
    comparison_df = pd.DataFrame(all_results).T
    comparison_df = comparison_df.round(4)
    
    print("\n=== æ‰€æœ‰æ¨¡å‹ç»“æœæ¯”è¾ƒ ===")
    print(comparison_df.to_string())
    
    # æ‰¾å‡ºæœ€ä½³æ¨¡å‹ï¼ˆåŸºäºä¸åŒæŒ‡æ ‡ï¼‰
    best_models = {}
    
    # æ£€æŸ¥æœ‰å“ªäº›æŒ‡æ ‡å¯ç”¨
    available_metrics = comparison_df.columns.tolist()
    
    if 'F1 (Micro)' in available_metrics:
        best_f1_micro = comparison_df['F1 (Micro)'].idxmax()
        best_models['f1_micro'] = {'model': best_f1_micro, 'score': float(comparison_df.loc[best_f1_micro, 'F1 (Micro)'])}
    
    if 'F1 (Macro)' in available_metrics:
        best_f1_macro = comparison_df['F1 (Macro)'].idxmax()
        best_models['f1_macro'] = {'model': best_f1_macro, 'score': float(comparison_df.loc[best_f1_macro, 'F1 (Macro)'])}
        
    if 'F1 (Weighted)' in available_metrics:
        best_f1_weighted = comparison_df['F1 (Weighted)'].idxmax()
        best_models['f1_weighted'] = {'model': best_f1_weighted, 'score': float(comparison_df.loc[best_f1_weighted, 'F1 (Weighted)'])}
    
    if 'Jaccard (Micro)' in available_metrics:
        best_jaccard = comparison_df['Jaccard (Micro)'].idxmax()
        best_models['jaccard_micro'] = {'model': best_jaccard, 'score': float(comparison_df.loc[best_jaccard, 'Jaccard (Micro)'])}
    
    if 'Hamming Loss' in available_metrics:
        best_hamming = comparison_df['Hamming Loss'].idxmin()  # è¶Šå°è¶Šå¥½
        best_models['hamming_loss'] = {'model': best_hamming, 'score': float(comparison_df.loc[best_hamming, 'Hamming Loss'])}
    
    # å…¼å®¹å•æ ‡ç­¾æŒ‡æ ‡
    if 'Accuracy' in available_metrics:
        best_accuracy = comparison_df['Accuracy'].idxmax()
        best_models['accuracy'] = {'model': best_accuracy, 'score': float(comparison_df.loc[best_accuracy, 'Accuracy'])}
    
    print(f"\n=== æœ€ä½³æ¨¡å‹ ===")
    for metric, info in best_models.items():
        print(f"{metric}: {info['model']} ({info['score']:.4f})")
    
    # ä¿å­˜æ€»ç»“æœ
    final_results = {
        'timestamp': datetime.now().isoformat(),
        'model_comparison': comparison_df.to_dict(),
        'best_models': best_models
    }
    
    with open(os.path.join(results_dir, 'final_comparison.json'), 'w', encoding='utf-8') as f:
        json.dump(final_results, f, ensure_ascii=False, indent=2)
    
    comparison_df.to_csv(os.path.join(results_dir, 'all_models_comparison.csv'))
    
    print(f"\nâœ“ æœ€ç»ˆæ¯”è¾ƒç»“æœå·²ä¿å­˜åˆ° {results_dir}/")
    return True

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='è¿è¡Œç²¾ç¥ç–¾ç—…è¯Šæ–­é¢„æµ‹baseline')
    parser.add_argument('--skip-preprocessing', action='store_true', 
                       help='è·³è¿‡æ•°æ®é¢„å¤„ç†æ­¥éª¤')
    parser.add_argument('--only-tfidf', action='store_true',
                       help='åªè¿è¡ŒTF-IDFæ¨¡å‹')
    parser.add_argument('--only-bert', action='store_true',
                       help='åªè¿è¡ŒChineseBERTæ¨¡å‹')
    parser.add_argument('--only-qwen3', action='store_true',
                       help='åªè¿è¡ŒQwen3æ¨¡å‹')
    parser.add_argument('--compare-only', action='store_true',
                       help='åªè¿›è¡Œç»“æœæ¯”è¾ƒï¼Œä¸è¿è¡Œæ¨¡å‹')
    
    args = parser.parse_args()
    
    print("ç²¾ç¥ç–¾ç—…è¾…åŠ©è¯Šæ–­ç»“æœé¢„æµ‹ - Baselineè¿è¡Œ")
    print("="*60)
    print(f"å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    success_count = 0
    total_steps = 0
    
    # åªæ¯”è¾ƒç»“æœ
    if args.compare_only:
        collect_and_compare_results()
        return
    
    # æ•°æ®é¢„å¤„ç†
    if not args.skip_preprocessing:
        total_steps += 1
        if run_data_preprocessing():
            success_count += 1
    
    # æ£€æŸ¥æ•°æ®æ˜¯å¦å­˜åœ¨
    if not os.path.exists('processed_data/train.csv'):
        print("âŒ æœªæ‰¾åˆ°é¢„å¤„ç†åçš„æ•°æ®ï¼Œè¯·å…ˆè¿è¡Œæ•°æ®é¢„å¤„ç†")
        return
    
    # è¿è¡ŒæŒ‡å®šçš„æ¨¡å‹
    if args.only_tfidf:
        total_steps += 1
        if run_tfidf_baseline():
            success_count += 1
    elif args.only_bert:
        total_steps += 1
        if run_chinesebert_baseline():
            success_count += 1
    elif args.only_qwen3:
        total_steps += 1
        if run_qwen3_baseline():
            success_count += 1
    else:
        # è¿è¡Œæ‰€æœ‰æ¨¡å‹
        total_steps += 3
        
        if run_tfidf_baseline():
            success_count += 1
        
        if run_chinesebert_baseline():
            success_count += 1
        
        if run_qwen3_baseline():
            success_count += 1
    
    # ç»“æœæ¯”è¾ƒ
    total_steps += 1
    if collect_and_compare_results():
        success_count += 1
    
    # æ€»ç»“
    print("\n" + "="*60)
    print("è¿è¡Œæ€»ç»“")
    print("="*60)
    print(f"å®Œæˆæ­¥éª¤: {success_count}/{total_steps}")
    print(f"ç»“æŸæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    if success_count == total_steps:
        print("ğŸ‰ æ‰€æœ‰æ­¥éª¤æˆåŠŸå®Œæˆ!")
    else:
        print("âš ï¸  éƒ¨åˆ†æ­¥éª¤å¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯")

if __name__ == "__main__":
    main() 